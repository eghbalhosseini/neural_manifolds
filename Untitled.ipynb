{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__cuda available  False\n",
      "__Python VERSION: 3.7.7 (default, May  6 2020, 04:59:01) \n",
      "[Clang 4.0.1 (tags/RELEASE_401/final)]\n",
      "__CUDNN VERSION: None\n",
      "__Number CUDA Devices: 0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import sys\n",
    "import os\n",
    "from torchvision import models\n",
    "from mftma.manifold_analysis_correlation import manifold_analysis_corr\n",
    "from mftma.utils.make_manifold_data import make_manifold_data\n",
    "from mftma.utils.activation_extractor import extractor\n",
    "from mftma.utils.analyze_pytorch import analyze\n",
    "import getpass\n",
    "import argparse\n",
    "from neural_manifold_utils import CFAR100_fake_dataset_mftma , save_dict\n",
    "from datetime import datetime\n",
    "print('__cuda available ',torch.cuda.is_available())\n",
    "print('__Python VERSION:', sys.version)\n",
    "print('__CUDNN VERSION:', torch.backends.cudnn.version())\n",
    "print('__Number CUDA Devices:', torch.cuda.device_count())\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchvision import datasets, transforms, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eghbalhosseini\n"
     ]
    }
   ],
   "source": [
    "user=getpass.getuser()\n",
    "print(user)\n",
    "if user=='eghbalhosseini':\n",
    "    save_dir='/Users/eghbalhosseini/MyData/neural_manifolds/network_training_on_synthetic/'\n",
    "    data_dir='/Users/eghbalhosseini/MyData/neural_manifolds/synthetic_datasets/'\n",
    "elif user=='ehoseini':\n",
    "    save_dir='/om/user/ehoseini/MyData/neural_manifolds/network_training_on_synthetic/'\n",
    "    data_dir='/om/user/ehoseini/MyData/neural_manifolds/synthetic_datasets/'\n",
    "datafile='synth_partition_nobj_50000_nclass_50_nfeat_3072_beta_0.01_sigma_1.50_norm_1.mat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<HDF5 dataset \"data\": shape (100000,), type \"<f8\"> is not a matlab type\n",
      "<HDF5 dataset \"ir\": shape (100000,), type \"<u8\"> is not a matlab type\n",
      "<HDF5 dataset \"jc\": shape (50051,), type \"<u8\"> is not a matlab type\n",
      "data type not supported: graph, uint32\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dataset = CFAR100_fake_dataset_mftma(data_dir=os.path.join(data_dir, datafile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mean = (0.5070751592371323, 0.48654887331495095, 0.4409178433670343)\n",
    "std = (0.2673342858792401, 0.2564384629170883, 0.27615047132568404)\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "dataset = datasets.CIFAR100('~/MyData/neural_manifolds', train=True, download=True,\n",
    "                   transform=transform_train)\n",
    "test_dataset = datasets.CIFAR100('~/MyData/neural_manifolds', train=False, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize(mean, std)\n",
    "                   ]))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1024, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_classes = 50\n",
    "examples_per_class = 100\n",
    "data = make_manifold_data(dataset, sampled_classes, examples_per_class, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "sampled_data = defaultdict(list)\n",
    "sampled_labels = np.random.choice(list(range(50)), size=sampled_classes, replace=False)\n",
    "idx = [i for i in range(len(dataset))]\n",
    "np.random.shuffle(idx)\n",
    "for i in idx:\n",
    "        sample, label = dataset[i]\n",
    "        if label in sampled_labels and len(sampled_data[label]) < examples_per_class:\n",
    "            sampled_data[label].append(sample)\n",
    "        # Check if enough samples have been drawn\n",
    "        complete = True\n",
    "        for s in sampled_labels:\n",
    "            if len(sampled_data[s]) < examples_per_class:\n",
    "                complete = False\n",
    "        if complete:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(sampled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path=save_dir+'VGG16_synthdata_'+train_dataset.structure+'_nclass_'+str(int(train_dataset.n_class))+'_n_exm_'+str(int(train_dataset.exm_per_class))\n",
    "model = models.vgg16(num_classes=train_dataset.n_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(model_save_path, map_location=device))\n",
    "model = model.to(device)\n",
    "model = model.eval()\n",
    "activations = extractor(model, data, layer_types=['Conv2d', 'Linear'])\n",
    "list(activations.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer, data, in activations.items():\n",
    "    X = [d.reshape(d.shape[0], -1).T for d in data]\n",
    "    # Get the number of features in the flattened data\n",
    "    N = X[0].shape[0]\n",
    "    # If N is greater than 5000, do the random projection to 5000 features\n",
    "    if N > 5000:\n",
    "        print(\"Projecting {}\".format(layer))\n",
    "        M = np.random.randn(5000, N)\n",
    "        M /= np.sqrt(np.sum(M * M, axis=1, keepdims=True))\n",
    "        X = [np.matmul(M, d) for d in X]\n",
    "    activations[layer] = X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capacities = []\n",
    "radii = []\n",
    "dimensions = []\n",
    "correlations = []\n",
    "for k, X, in activations.items():\n",
    "    # Analyze each layer's activations\n",
    "    a, r, d, r0, K = manifold_analysis_corr(X, 0, 300, n_reps=1)\n",
    "    # Compute the mean values\n",
    "    a = 1 / np.mean(1 / a)\n",
    "    r = np.mean(r)\n",
    "    d = np.mean(d)\n",
    "    print(\"{} capacity: {:4f}, radius {:4f}, dimension {:4f}, correlation {:4f}\".format(k, a, r, d, r0))\n",
    "\n",
    "    # Store for later\n",
    "    capacities.append(a)\n",
    "    radii.append(r)\n",
    "    dimensions.append(d)\n",
    "    correlations.append(r0)\n",
    "names = list(activations.keys())\n",
    "names = [n.split('_')[1] + ' ' + n.split('_')[2] for n in names]\n",
    "# save the results:\n",
    "current_time = datetime.now().strftime('%b%d_%H-%M-%S')\n",
    "results_file = os.path.join(save_dir,'mftma_'+model_save_path+'_'+current_time)\n",
    "data_ = {'capacities': capacities,\n",
    "             'radii': radii,\n",
    "             'dimensions': dimensions,\n",
    "             'correlations': correlations,\n",
    "             'names': names,\n",
    "             'analyze_exm_per_class': examples_per_class,\n",
    "             'analyze_n_class': sampled_classes\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_save_path=save_dir+'mftma_VGG16_synthdata_'+train_dataset.structure+'_nclass_'+str(int(train_dataset.n_class))+'_n_exm_'+str(int(train_dataset.exm_per_class))+'_'+current_time\n",
    "\n",
    "save_dict(data_, result_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_save_path=save_dir+'mftma_VGG16_synthdata_'+train_dataset.structure+'_nclass_'+str(int(train_dataset.n_class))+'_n_exm_'+str(int(train_dataset.exm_per_class))+'_'+current_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = (0.5070751592371323, 0.48654887331495095, 0.4409178433670343)\n",
    "std = (0.2673342858792401, 0.2564384629170883, 0.27615047132568404)\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "train_dataset = datasets.CIFAR100('../data', train=True, download=True,\n",
    "                   transform=transform_train)\n",
    "test_dataset = datasets.CIFAR100('../data', train=False, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize(mean, std)\n",
    "                   ]))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_manifold",
   "language": "python",
   "name": "python_manifold"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
