{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'scipy.linalg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-96d80066778a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmftma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanifold_analysis_correlation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmanifold_analysis_corr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmftma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_manifold_data\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmake_manifold_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmftma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation_extractor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mextractor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/MyCodes/neural_manifolds_replicaMFT/mftma/manifold_analysis_correlation.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mqr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfunctools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'scipy.linalg'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import os\n",
    "import pandas as pd \n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import Dataset\n",
    "from mftma.manifold_analysis_correlation import manifold_analysis_corr\n",
    "from mftma.utils.make_manifold_data import make_manifold_data\n",
    "from mftma.utils.activation_extractor import extractor\n",
    "from mftma.utils.analyze_pytorch import analyze\n",
    "import getpass\n",
    "import mat73\n",
    "import scipy\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "import scipy.io as sio   \n",
    "from scipy.io import loadmat\n",
    "class CFAR100_fake_dataset(Dataset):\n",
    "    def __init__(self, data_dir=None):\n",
    "        self.data_dir=data_dir\n",
    "        self.dat , self.target=self.load_data()\n",
    "        self.n_samples=self.dat.shape[0]\n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "    def __getitem__(self, idx):\n",
    "        #item=np.expand_dims(self.dat[idx],axis=0)\n",
    "        item=self.dat[idx]\n",
    "        targ=np.squeeze(self.target[idx])\n",
    "        return (torch.tensor(item,dtype=torch.float), targ)\n",
    "    def load_data(self):\n",
    "        try:\n",
    "            annot=loadmat(self.data_dir) \n",
    "            ops_struct=annot['ops_out']\n",
    "            vals=ops_struct[0,0]\n",
    "        except: \n",
    "            data_dict = mat73.loadmat(self.data_dir)\n",
    "            vals=data_dict['ops_out']\n",
    "        dat=vals['data']\n",
    "        self.vals=vals\n",
    "        self.adj=vals['Adjacency']\n",
    "        dat_new=dat[:,range(3*32*32)]\n",
    "        dat_new=np.reshape(dat_new,(-1,3,32,32))\n",
    "        target=np.double(np.transpose(vals['class_id'])-1.0)\n",
    "        return dat_new, target \n",
    "    \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'scipy.linalg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-810a6e7acbc7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'scipy.linalg'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user=getpass.getuser()\n",
    "print(user)\n",
    "if user=='eghbalhosseini':\n",
    "    save_dir='/Users/eghbalhosseini/MyData/neural_manifolds/VGG16_training_on_synthetic/'\n",
    "    data_dir='/Users/eghbalhosseini/MyData/neural_manifolds/VGG16_training_on_synthetic/'\n",
    "elif user=='ehoseini':\n",
    "    save_dir='/om/user/ehoseini/MyData/neural_manifolds/VGG16_training_on_synthetic/'\n",
    "    data_dir='/om/user/ehoseini/MyData/neural_manifolds/'\n",
    "\n",
    "#data_file='synthtree_nobj_50000_nclass_50_nfeat_3072_norm_1.mat'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Partition_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset \n",
    "data_file='synthpartition_nobj_50000_nclass_50_nfeat_3072_norm_1.mat'\n",
    "train_dataset=CFAR100_fake_dataset(data_dir=os.path.join(data_dir,data_file))\n",
    "# extract samples \n",
    "sampled_classes = 50\n",
    "examples_per_class = 25\n",
    "data = make_manifold_data(train_dataset, sampled_classes, examples_per_class,max_class=50, seed=0)\n",
    "data = [d.to(device) for d in data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load model and extract activations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path=save_dir+'VGG16_synthdata_'+train_dataset.vals.structure+'_nclass_'+str(int(train_dataset.vals.n_class))+'_n_exm_'+str(int(train_dataset.vals.exm_per_class))\n",
    "model = models.vgg16(num_classes=50)\n",
    "model.load_state_dict(torch.load(model_save_path,map_location=device))\n",
    "model = model.to(device)\n",
    "model = model.eval()\n",
    "activations = extractor(model, data, layer_types=['Conv2d', 'Linear'])\n",
    "list(activations.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(activations['layer_0_Input'][1][1]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir=\"/Users/eghbalhosseini/Desktop/\"\n",
    "epoch_id=1\n",
    "layer_num=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "datafile = os.path.join(save_dir,train_dir, 'train_epoch_' + str(epoch_id))\n",
    "epoch_dat = pd.read_pickle(datafile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer, data, in activations.items():\n",
    "    X = [d.reshape(d.shape[0], -1).T for d in data]\n",
    "    # Get the number of features in the flattened data\n",
    "    N = X[0].shape[0]\n",
    "    # If N is greater than 5000, do the random projection to 5000 features\n",
    "    if N > 5000:\n",
    "        print(\"Projecting {}\".format(layer))\n",
    "        M = np.random.randn(5000, N)\n",
    "        M /= np.sqrt(np.sum(M*M, axis=1, keepdims=True))\n",
    "        X = [np.matmul(M, d) for d in X]\n",
    "    activations[layer] = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capacities = []\n",
    "radii = []\n",
    "dimensions = []\n",
    "correlations = []\n",
    "\n",
    "for k, X, in activations.items():\n",
    "    # Analyze each layer's activations\n",
    "    a, r, d, r0, K = manifold_analysis_corr(X, 0, 300, n_reps=1)\n",
    "    \n",
    "    # Compute the mean values\n",
    "    a = 1/np.mean(1/a)\n",
    "    r = np.mean(r)\n",
    "    d = np.mean(d)\n",
    "    print(\"{} capacity: {:4f}, radius {:4f}, dimension {:4f}, correlation {:4f}\".format(k, a, r, d, r0))\n",
    "    \n",
    "    # Store for later\n",
    "    capacities.append(a)\n",
    "    radii.append(r)\n",
    "    dimensions.append(d)\n",
    "    correlations.append(r0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 4, figsize=(18, 4))\n",
    "\n",
    "axes[0].plot(capacities, linewidth=5)\n",
    "axes[1].plot(radii, linewidth=5)\n",
    "axes[2].plot(dimensions, linewidth=5)\n",
    "axes[3].plot(correlations, linewidth=5)\n",
    "\n",
    "axes[0].set_ylabel(r'$\\alpha_M$', fontsize=18)\n",
    "axes[1].set_ylabel(r'$R_M$', fontsize=18)\n",
    "axes[2].set_ylabel(r'$D_M$', fontsize=18)\n",
    "axes[3].set_ylabel(r'$\\rho_{center}$', fontsize=18)\n",
    "\n",
    "names = list(activations.keys())\n",
    "names = [n.split('_')[1] + ' ' + n.split('_')[2] for n in names]\n",
    "for ax in axes:\n",
    "    ax.set_xticks([i for i, _ in enumerate(names)])\n",
    "    ax.set_xticklabels(names, rotation=90, fontsize=16)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Tree dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset \n",
    "data_file='synthtree_nobj_50000_nclass_50_nfeat_3072_norm_1.mat'\n",
    "train_dataset=CFAR100_fake_dataset(data_dir=os.path.join(data_dir,data_file))\n",
    "# extract samples \n",
    "sampled_classes = 50\n",
    "examples_per_class = 50\n",
    "data = make_manifold_data(train_dataset, sampled_classes, examples_per_class,max_class=50, seed=0)\n",
    "data = [d.to(device) for d in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path=save_dir+'VGG16_synthdata_'+train_dataset.vals.structure+'_nclass_'+str(int(train_dataset.vals.n_class))+'_n_exm_'+str(int(train_dataset.vals.exm_per_class))\n",
    "model = models.vgg16(num_classes=50)\n",
    "model.load_state_dict(torch.load(model_save_path,map_location=device))\n",
    "model = model.to(device)\n",
    "model = model.eval()\n",
    "activations = extractor(model, data, layer_types=['Conv2d', 'Linear'])\n",
    "list(activations.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer, data, in activations.items():\n",
    "    X = [d.reshape(d.shape[0], -1).T for d in data]\n",
    "    # Get the number of features in the flattened data\n",
    "    N = X[0].shape[0]\n",
    "    # If N is greater than 5000, do the random projection to 5000 features\n",
    "    if N > 5000:\n",
    "        print(\"Projecting {}\".format(layer))\n",
    "        M = np.random.randn(5000, N)\n",
    "        M /= np.sqrt(np.sum(M*M, axis=1, keepdims=True))\n",
    "        X = [np.matmul(M, d) for d in X]\n",
    "    activations[layer] = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capacities = []\n",
    "radii = []\n",
    "dimensions = []\n",
    "correlations = []\n",
    "\n",
    "for k, X, in activations.items():\n",
    "    # Analyze each layer's activations\n",
    "    a, r, d, r0, K = manifold_analysis_corr(X, 0, 300, n_reps=1)\n",
    "    \n",
    "    # Compute the mean values\n",
    "    a = 1/np.mean(1/a)\n",
    "    r = np.mean(r)\n",
    "    d = np.mean(d)\n",
    "    print(\"{} capacity: {:4f}, radius {:4f}, dimension {:4f}, correlation {:4f}\".format(k, a, r, d, r0))\n",
    "    \n",
    "    # Store for later\n",
    "    capacities.append(a)\n",
    "    radii.append(r)\n",
    "    dimensions.append(d)\n",
    "    correlations.append(r0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 4, figsize=(18, 4))\n",
    "\n",
    "axes[0].plot(capacities, linewidth=5)\n",
    "axes[1].plot(radii, linewidth=5)\n",
    "axes[2].plot(dimensions, linewidth=5)\n",
    "axes[3].plot(correlations, linewidth=5)\n",
    "\n",
    "axes[0].set_ylabel(r'$\\alpha_M$', fontsize=18)\n",
    "axes[1].set_ylabel(r'$R_M$', fontsize=18)\n",
    "axes[2].set_ylabel(r'$D_M$', fontsize=18)\n",
    "axes[3].set_ylabel(r'$\\rho_{center}$', fontsize=18)\n",
    "\n",
    "names = list(activations.keys())\n",
    "names = [n.split('_')[1] + ' ' + n.split('_')[2] for n in names]\n",
    "for ax in axes:\n",
    "    ax.set_xticks([i for i, _ in enumerate(names)])\n",
    "    ax.set_xticklabels(names, rotation=90, fontsize=16)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36_manifold",
   "language": "python",
   "name": "py36_manifold"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
