{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__cuda available  True\n",
      "__Python VERSION: 3.6.10 (default, Apr 23 2020, 15:24:07) \n",
      "[GCC 8.3.0]\n",
      "__CUDNN VERSION: 7603\n",
      "__Number CUDA Devices: 4\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import copy\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import Dataset\n",
    "from mftma.utils.make_manifold_data import make_manifold_data\n",
    "from mftma.utils.activation_extractor import extractor\n",
    "from neural_manifold_utils import train, test, save_dict, sub_data, create_manifold_data\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import os, sys\n",
    "import socket\n",
    "from datetime import datetime\n",
    "import getpass\n",
    "import numpy as np \n",
    "print('__cuda available ',torch.cuda.is_available())\n",
    "print('__Python VERSION:', sys.version)\n",
    "print('__CUDNN VERSION:', torch.backends.cudnn.version())\n",
    "print('__Number CUDA Devices:', torch.cuda.device_count())\n",
    "\n",
    "import mat73\n",
    "#from mftma.manifold_analysis_correlation import manifold_analysis_corr\n",
    "#from mftma.utils.make_manifold_data import make_manifold_data\n",
    "from mftma.utils.activation_extractor import extractor\n",
    "#from mftma.utils.analyze_pytorch import analyze\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ehoseini\n",
      "<HDF5 dataset \"data\": shape (100124,), type \"<f8\"> is not a matlab type\n",
      "<HDF5 dataset \"ir\": shape (100124,), type \"<u8\"> is not a matlab type\n",
      "<HDF5 dataset \"jc\": shape (50064,), type \"<u8\"> is not a matlab type\n",
      "data type not supported: graph, uint32\n",
      "data type not supported: graph, uint32\n"
     ]
    }
   ],
   "source": [
    "user=getpass.getuser()\n",
    "print(user)\n",
    "if user=='eghbalhosseini':\n",
    "    save_dir='/Users/eghbalhosseini/MyData/neural_manifolds/network_training_on_synthetic/'\n",
    "    data_dir='/Users/eghbalhosseini/MyData/neural_manifolds/synthetic_datasets/'\n",
    "elif user=='ehoseini':\n",
    "    save_dir='/om/user/ehoseini/MyData/neural_manifolds/network_training_on_synthetic/'\n",
    "    data_dir='/om/user/ehoseini/MyData/neural_manifolds/synthetic_datasets/'\n",
    "datafile=\"synth_tree_nobj_50000_nclass_50_nfeat_3072_beta_0.01_sigma_1.50_norm_1.mat\"\n",
    "\n",
    "batch_size_train=64\n",
    "batch_size_test=64\n",
    "resize = True\n",
    "epochs=2\n",
    "exm_per_class=10\n",
    "save_epochs=False\n",
    "momentum=0.5\n",
    "lr=0.01\n",
    "gamma=0.7\n",
    "log_interval=75\n",
    "test_split = .2\n",
    "shuffle_dataset = True\n",
    "random_seed = 1\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dataset = sub_data(data_path=os.path.join(data_dir, datafile))\n",
    "if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "# Creating data indices for training and test splits:\n",
    "random_seed=1\n",
    "test_split = .2\n",
    "dataset_size = len(dataset)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(test_split * dataset_size))\n",
    "if shuffle_dataset :\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, test_indices = indices[split:], indices[:split]\n",
    "# Define transforms\n",
    "transform_2D = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "# train_dataset = ApplyTransform(train_dataset, transform=train_transform)\n",
    "# Creating PT data samplers and loaders:\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "test_sampler = SubsetRandomSampler(test_indices)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size_train, sampler=train_sampler)\n",
    "test_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size_test,sampler=test_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hierarchy=len(dataset.hierarchical_target)\n",
    "hier_classes = [x.astype(int) for x in dataset.hierarchical_target]\n",
    "hier_n_class = [int(max(x) + 1) for x in hier_classes]\n",
    "hier_dataset=[]\n",
    "for idx, x in enumerate(hier_classes):\n",
    "    dat_mfmta = []\n",
    "    dat_mtmfa = copy.deepcopy(dataset)\n",
    "    dat_mtmfa.targets = hier_classes[idx]\n",
    "    hier_dataset.append(copy.deepcopy(dat_mtmfa))\n",
    "\n",
    "hier_sample_mtmfa= [create_manifold_data(x, hier_n_class[idx], exm_per_class, seed=0) for idx, x in enumerate(hier_dataset)]\n",
    "hier_sample_mtmfa=[[d.to(device) for d in data] for data in hier_sample_mtmfa]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_spec = {'train_batch_size': batch_size_train,\n",
    "                  'test_batch_size': batch_size_test,\n",
    "                  'num_epochs': epochs,\n",
    "                  'structure': dataset.structure,\n",
    "                  'n_class': dataset.n_class,\n",
    "                  'exm_per_class': dataset.exm_per_class,\n",
    "                  'beta': dataset.beta,\n",
    "                  'sigma': dataset.sigma,\n",
    "                  'norm': dataset.is_norm,\n",
    "                  'log_interval':log_interval,\n",
    "                  'is_cuda':torch.cuda.is_available()\n",
    "                  }\n",
    "\n",
    "    # build model\n",
    "\n",
    "model = models.vgg16(num_classes=dataset.n_class)\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "    # create train log for tensorflow\n",
    "current_time = datetime.now().strftime('%b%d_%H-%M-%S')\n",
    "log_dir = os.path.join(save_dir, 'runs', current_time + '_' + socket.gethostname())\n",
    "    #writer = SummaryWriter(log_dir=log_dir)\n",
    "    #writer.add_hparams(hparam_dict=train_spec, metric_dict={})\n",
    "    # do the training :\n",
    "train_test_accu=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ = {'activations_cell': [],\n",
    "             'train_spec': train_spec,\n",
    "             'train_test_data': [],\n",
    "             'train_success':False\n",
    "             }\n",
    "model_dir=save_dir+'train_VGG16_synthdata_'+dataset.structure+'_nclass_'+str(int(dataset.n_class))+'_n_exm_'+str(int(dataset.exm_per_class))\n",
    "if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader.sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: [4800/50000 (12%)]\\Loss: 3.915713, Train Accuracy: (2%)\n",
      "Train Epoch: [9600/50000 (24%)]\\Loss: 3.911180, Train Accuracy: (3%)\n",
      "Train Epoch: [14400/50000 (36%)]\\Loss: 3.912959, Train Accuracy: (2%)\n",
      "Train Epoch: [19200/50000 (48%)]\\Loss: 3.910235, Train Accuracy: (2%)\n",
      "Train Epoch: [24000/50000 (60%)]\\Loss: 3.916163, Train Accuracy: (0%)\n",
      "Train Epoch: [28800/50000 (72%)]\\Loss: 3.909770, Train Accuracy: (8%)\n",
      "Train Epoch: [33600/50000 (84%)]\\Loss: 3.912319, Train Accuracy: (0%)\n",
      "Train Epoch: [38400/50000 (96%)]\\Loss: 3.915257, Train Accuracy: (3%)\n",
      "couldnt reformat the data\n",
      "\n",
      "Test set epoch 1: Average loss: 0.7825, Accuracy: 184/10000 (2%)\n",
      "\n",
      "Train Epoch: [4800/50000 (12%)]\\Loss: 3.910552, Train Accuracy: (2%)\n",
      "Train Epoch: [9600/50000 (24%)]\\Loss: 3.913121, Train Accuracy: (2%)\n",
      "Train Epoch: [14400/50000 (36%)]\\Loss: 3.906315, Train Accuracy: (2%)\n",
      "Train Epoch: [19200/50000 (48%)]\\Loss: 3.913738, Train Accuracy: (3%)\n",
      "Train Epoch: [24000/50000 (60%)]\\Loss: 3.909599, Train Accuracy: (2%)\n",
      "Train Epoch: [28800/50000 (72%)]\\Loss: 3.912190, Train Accuracy: (3%)\n",
      "Train Epoch: [33600/50000 (84%)]\\Loss: 3.912912, Train Accuracy: (2%)\n",
      "Train Epoch: [38400/50000 (96%)]\\Loss: 3.910111, Train Accuracy: (0%)\n",
      "couldnt reformat the data\n",
      "\n",
      "Test set epoch 2: Average loss: 0.7825, Accuracy: 191/10000 (2%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, epochs + 1):\n",
    "        data_ = {'activations_cell': [],\n",
    "                 'train_spec': train_spec,\n",
    "                 'train_accuracy': [],\n",
    "                 'test_accuracy':[],\n",
    "                 'train_success': False,\n",
    "                 'epoch':epoch}\n",
    "        train_test_data = []\n",
    "        epoch_dat = train(epoch, model, device, train_loader, test_loader, optimizer, train_spec)\n",
    "        test_accuracy = test(model, device, test_loader, epoch)\n",
    "        if test_accuracy > 70:\n",
    "            train_success = True\n",
    "        else:\n",
    "            train_success = False\n",
    "        # extract activation\n",
    "        model = model.eval()\n",
    "        activations_cell = [extractor(model, x, layer_types=['Conv2d', 'Linear']) for x in hier_sample_mtmfa]\n",
    "        data_['train_accuracy']=epoch_dat['train_acc']\n",
    "        data_['test_accuray']=test_accuracy\n",
    "        data_['activations_cell'] = activations_cell\n",
    "        data_['train_success'] = train_success\n",
    "        epoch_save_path = os.path.join(model_dir, 'train_epoch_' + str(epoch))\n",
    "        save_dict(data_, epoch_save_path)\n",
    "        if train_success:\n",
    "            print('successful training')\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activations_cell=[extractor(model,x,layer_types=['Conv2d', 'Linear']) for x in hier_sample_mtmfa]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=(activations_cell[0]['layer_0_Input'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"%d bytes\" % (17*10*n.size * n.itemsize+17*50*m.size * m.itemsize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch,model, device, train_loader,test_loader, optimizer,train_spec):\n",
    "    model.train()\n",
    "    test_accuracies = []\n",
    "    train_accuracies = []\n",
    "    fcs=[]\n",
    "    targets=[]\n",
    "    batchs=[]\n",
    "    log_interval=train_spec['log_interval']\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        output = torch.nn.functional.log_softmax(output, dim=1)\n",
    "        loss = torch.nn.functional.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (batch_idx % log_interval == 0) & (batch_idx!=0):\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct = pred.eq(target.view_as(pred)).sum().item()\n",
    "            accuracy_train = (100. * correct / len(target))\n",
    "            train_accuracies.append(accuracy_train)\n",
    "            print('Train Epoch: [{}/{} ({:.0f}%)]\\Loss: {:.6f}, Train Accuracy: ({:.0f}%)'.format(\n",
    "                 batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item(),\n",
    "                 100. * correct / len(target)))\n",
    "    epoch_dat = {\n",
    "        \"fc\": fcs,\n",
    "        \"target\": target,\n",
    "        \"batch\":  batchs,\n",
    "        \"epoch\": epoch,\n",
    "        \"test_acc\": test_accuracies,\n",
    "        \"train_acc\": train_accuracies}\n",
    "\n",
    "    # if is_cuda:/\n",
    "    if train_spec['is_cuda']:\n",
    "        try :\n",
    "            epoch_dat['test_acc'] = np.concatenate(epoch_dat['test_acc'])\n",
    "            epoch_dat['train_acc'] = np.concatenate(epoch_dat['train_acc'])\n",
    "            epoch_dat['fc'] = np.concatenate(epoch_dat['fc'], axis=0)\n",
    "            epoch_dat['target'] = np.concatenate(epoch_dat['target'])\n",
    "            epoch_dat['batch'] = np.concatenate(epoch_dat['batch'])\n",
    "        except: \n",
    "            print('couldnt reformat the data')\n",
    "    return epoch_dat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
